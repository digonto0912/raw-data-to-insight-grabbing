{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Reddit Analysis Agent - Google Colab Setup\n",
                "\n",
                "This notebook sets up the environment to run the \"Elite Anthropologist\" AI agent using **Ollama** and **Mistral 7B** completely free on Google Colab's CPU/GPU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Ollama & Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "# Install Python dependencies\n",
                "!pip install langchain langchain-ollama pydantic python-dotenv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Start Ollama Server & Pull Mistral 7B\n",
                "We need to start the Ollama server in the background and then pull the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import time\n",
                "\n",
                "# Start Ollama in the background\n",
                "process = subprocess.Popen([\"ollama\", \"serve\"])\n",
                "time.sleep(5)  # Give it a few seconds to start\n",
                "\n",
                "# Pull Mistral 7B (this may take a few minutes)\n",
                "!ollama pull mistral"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Upload Project Files\n",
                "Upload the `project_files.zip` you created. This cell unzips it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!unzip -o project_files.zip"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run the Agent\n",
                "Now we run the main script. Make sure `USE_OLLAMA = True` is set in `main.py` (it should be by default)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python main.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Download Results\n",
                "Zip the results and download them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!zip -r analysis_results.zip analysis_results/\n",
                "from google.colab import files\n",
                "files.download('analysis_results.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}